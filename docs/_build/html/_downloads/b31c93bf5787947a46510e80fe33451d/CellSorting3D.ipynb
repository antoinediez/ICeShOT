{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Cell sorting in 3D\n\nThis script simulates 3D cell aggregates with the following weighted $L^2$ cost and force for the cell $i$\n\n\\begin{align}c(x,x_i) = \\frac{\\gamma_{i0}}{R_i} |x - x_i|^2\\end{align}\n\n\\begin{align}F_{i\\leftarrow j} = \\int_{\\Gamma_{ij}} \\left(\\gamma_{ij} |\\kappa| + \\frac{\\eta_{ij}}{|x_i - x_j|} \\right) \\vec{n}\\mathrm{d}\\sigma\\end{align}\n\n\\begin{align}F_i = \\sum_{j=0}^N F_{i\\leftarrow j} - \\frac{1}{N_i}\\sum_{k\\in\\mathscr{N}_i} F_{k\\leftarrow 0}\\end{align}\nwhere $\\gamma_{ij}$ and $\\eta_{ij}$ are surface tension parameters, $R_i$ is the radius of cell $i$, $\\Gamma_{ij}$ is the interface between cells $i$ and $j$, $\\kappa$ is the local mean curvature and $\\vec{n}$ is the inward normal of cell $\\mathscr{L}_i$.\n\n\nIn this script, there are two cell types (indexed by $b$ and $o$) and the surface tension parameters only depend on the type. Varying them lead to various cell sorting phenomena which can be classified according to the following ratios\n\n\\begin{align}\\overline{\\eta} = \\frac{\\eta_{ob}}{\\eta_{oo}},\\quad \\overline{\\gamma} = \\frac{\\gamma_o}{\\gamma_b},\\quad \\overline{k} = \\frac{\\gamma_b\\eta_{oo}}{\\gamma_o\\eta_{bb}}\\end{align}\n\n\nRepresentative situations are obtained as follow: \n\n**Separation** : $\\overline{\\eta} = 3, \\quad \\overline{\\gamma} = 2,\\quad \\overline{k} = 1$\n\n.. video:: ../../_static/SMV11_3Dsorting_separation.mp4\n    :autoplay:\n    :loop:\n    :muted:\n    :width: 400\n\n**Checkerboard** : $\\overline{\\eta} = 0.3, \\quad \\overline{\\gamma} = 2,\\quad \\overline{k} = 1$\n\n\n.. video:: ../../_static/SMV12_3Dsorting_checkerboard.mp4\n    :autoplay:\n    :loop:\n    :muted:\n    :width: 400\n\n\n**Internalization** : $\\overline{\\eta} = 3, \\quad \\overline{\\gamma} = 2,\\quad \\overline{k}\\overline{\\gamma}\\overline{\\eta} = 1$\n\n\n.. video:: ../../_static/SMV13_3Dsorting_internalization.mp4\n    :autoplay:\n    :loop:\n    :muted:\n    :width: 400\n\n**Engulfment with initial segregation** : $ \\overline{\\eta} = 3, \\quad \\overline{\\gamma} = 2,\\quad \\overline{k}\\overline{\\gamma}\\overline{\\eta} = 1$\n\n.. video:: ../../_static/SMV14_3Dsorting_engulfment.mp4\n    :autoplay:\n    :loop:\n    :muted:\n    :width: 400\n\n\nNote: this script only save the mesh data, that can then be loaded in VTK, PyVista, Paraview etc. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_path = '_static/3Dengulfment.png'\n\nimport os\nimport sys\nsys.path.append(\"..\")\nimport time\nimport pickle\nimport math\nimport torch\nimport numpy as np\nfrom matplotlib import colors\nfrom matplotlib.colors import ListedColormap\nfrom iceshot import cells\nfrom iceshot import costs\nfrom iceshot import OT\nfrom iceshot.OT import OT_solver\nfrom iceshot import plot_cells\nfrom iceshot import sample\nfrom iceshot import utils\nimport tifffile as tif\nimport pyvista as pv\nimport vtk as vtk\nfrom pyvista.core import _vtk_core as _vtk\nfrom pyvista.core.filters import _get_output, _update_alg\nfrom typing import Literal, Optional, cast\nfrom pyvista.core.utilities.arrays import FieldAssociation, set_default_active_scalars\n\n\npv.start_xvfb()\npv.set_jupyter_backend('static')\n\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n    device = \"cuda\"\n  \ndef run_simu(params,title=None,init=\"uniform\"):\n\n    ot_algo = OT.LBFGSB\n\n    N = 128\n    N1 = 64\n    \n    # N = 96\n    # N1 = 24\n\n    M = 256\n    dim = 3\n\n    R0 = 1.0\n    R00 = 0.055\n    RN = torch.ones(N)*R00\n    vol_x = 4./3.*math.pi*RN**3\n    \n    if init == \"uniform\":\n        seeds = 0.5 + 0.14*2.*(torch.rand((N,dim))-0.5)\n    elif init == \"split\":\n        seeds1 = 0.4 + 0.1*2.*(torch.rand((N1,dim))-0.5)\n        seeds2 = 0.6 + 0.1*2.*(torch.rand((N-N1,dim))-0.5)\n        seeds = torch.cat((seeds1,seeds2),dim=0)\n\n    #================ SURFACE TENSION PARAMETERS ==================#\n\n    gb = params[\"gb\"]\n    g12 = params[\"g12\"]\n    g11 = params[\"g11\"]\n    g22 = params[\"g22\"]\n    g10 = params[\"g10\"]\n    g20 = params[\"g20\"]\n    b12 = params[\"b12\"]\n    b11 = params[\"b11\"]\n    b22 = params[\"b22\"]\n    \n\n    print(\"===============================================================\")\n    print(\"Surface Tension Parameters\",flush=True)\n    print(f\"g12={g12}\",flush=True)\n    print(f\"g11={g11}\",flush=True)\n    print(f\"g22={g22}\",flush=True)\n    print(f\"g10={g10}\",flush=True)\n    print(f\"g20={g20}\",flush=True)\n    print(f\"b12={b12}\",flush=True)\n    print(f\"b11={b11}\",flush=True)\n    print(f\"b22={b22}\",flush=True)\n\n    print(\"Compaction Tension Parameters\",flush=True)\n    print(f\"k10={0.5*b11/g10}\",flush=True)\n    print(f\"k20={0.5*b22/g20}\",flush=True)\n    print(f\"k12={0.5*b11/g12}\",flush=True)\n    \n    \n    r_b1 = params[\"r_b1\"]\n    r_g1 = params[\"r_g1\"]\n    r_k1 = params[\"r_k1\"]\n    print(\"Ratios\",flush=True)\n    print(f\"r_b1 = {r_b1}\")\n    print(f\"r_g1 = {r_g1}\")\n    print(f\"r_k1 = {r_k1}\")\n\n    if title is None:\n        simu_name = f\"simu_3Dsorting_b_{r_b1}_g_{r_g1}_k_{r_k1}\"\n    else:\n        simu_name = f\"simu_3Dsorting_\" + title\n    os.mkdir(simu_name)\n    os.mkdir(simu_name+\"/frames\")\n    os.mkdir(simu_name+\"/data\")\n    print(\"===============================================================\")\n\n\n    #===============================================#\n\n    tau = 0.0\n    sc = R0/RN\n    sc[N1:] *= g20/g10\n\n    source = sample.sample_grid(M,dim=dim)\n\n    simu = cells.Cells(\n        seeds=seeds,source=source,\n        vol_x=vol_x,extra_space=\"void\",jct_method='Kmin'\n    )\n\n\n    cost_params = {\n        \"p\" : 2,\n        \"scaling\" : \"constant\",\n        \"C\" : 1.0\n    }\n\n    solver = OT_solver(\n        n_sinkhorn=800,n_sinkhorn_last=2000,n_lloyds=10,s0=2.0,\n        cost_function=costs.power_cost,cost_params=cost_params\n    )\n\n    T = 4.0\n    dt = 0.0003   # This is too small! \n    plot_every = 20\n    save_every = 1\n    t = 0.0\n    t_iter = 0\n    t_plot = 0\n\n\n    #===========================================================#\n\n    def radius(simu):\n        return torch.sqrt(simu.volumes[:-1]/math.pi) if simu.d==2 else (simu.volumes[:-1]/(4./3.*math.pi)) ** (1./3.)\n\n\n    def compute_mesh(img):\n        img = np.pad(img,1,mode='constant',constant_values=-2.0)\n        vol = pv.wrap(img)\n        alg = vtk.vtkSurfaceNets3D()\n        set_default_active_scalars(vol)  # type: ignore\n        field, scalars = vol.active_scalars_info  # type: ignore\n\n        # args: (idx, port, connection, field, name)\n        alg.SetInputArrayToProcess(0, 0, 0, field.value, scalars)  \n        alg.SetInputData(vol)\n        alg.GenerateValues(simu.N_cells, 0, simu.N_cells-1)\n\n        # Suppress improperly used INFO for debugging messages in vtkSurfaceNets3D\n        verbosity = _vtk.vtkLogger.GetCurrentVerbosityCutoff()\n        _vtk.vtkLogger.SetStderrVerbosity(_vtk.vtkLogger.VERBOSITY_OFF)\n        _update_alg(alg, False, 'Performing Labeled Surface Extraction')\n        # Restore the original vtkLogger verbosity level\n        _vtk.vtkLogger.SetStderrVerbosity(verbosity)\n        surfaces = cast(pv.PolyData, pv.wrap(alg.GetOutput()))\n        surfaces = surfaces.smooth_taubin(n_iter=100, pass_band=0.05, normalize_coordinates=True)\n        surfaces = surfaces.compute_normals(consistent_normals=True,\n                                            auto_orient_normals=True,\n                                            flip_normals=True,\n                                            non_manifold_traversal=False)\n        surfaces = surfaces.compute_cell_sizes()\n        surfaces[\"Curvature\"] = surfaces.curvature()\n        surfaces[\"Particle\"] = surfaces[\"BoundaryLabels\"].min(axis=1)*(surfaces[\"BoundaryLabels\"].min(axis=1)>=0) + surfaces[\"BoundaryLabels\"].max(axis=1)*(surfaces[\"BoundaryLabels\"].min(axis=1)<0)\n        surfaces.set_active_scalars(\"Particle\")\n        surfaces = surfaces.point_data_to_cell_data()\n        return surfaces\n\n    def extract_stuff(surfaces,M=M,simu=simu,eps=None):\n        normals = torch.tensor(surfaces[\"Normals\"])\n        normals /= torch.norm(normals,dim=1)[:,None]\n        lab = torch.tensor(surfaces[\"BoundaryLabels\"])\n        area = torch.tensor(surfaces[\"Area\"])/((M+2)**2)\n        curv = torch.tensor(surfaces[\"Curvature\"])*(M+2)\n        centers = torch.tensor((surfaces.cell_centers().points - 1.0/(M+2))/M)\n        return good_stuff(simu,(normals, lab, area, curv, centers),eps=eps)\n\n    def good_stuff(simu,stuff,eps=None):\n        return reorient_normals(simu,stuff,eps=eps)\n\n    def belongs_to(simu,x):\n        M = round(simu.M_grid ** (1/simu.d))\n        ijk = torch.floor(x*M).type(torch.long)\n        ijk = torch.clamp(ijk,0,M-1)\n        lab = ijk[:,0]*M**2 + ijk[:,1]*M + ijk[:,2]\n        labels = simu.labels[lab]\n        labels[labels > simu.N_cells-1] = -1.0\n        return labels\n\n    def reorient_normals(simu,stuff,eps=None):\n        # normals should go from lab[:,0] to lab[:,1]\n        normals, lab, area, curv, centers = stuff\n        if eps is None:\n            eps = 3.0/((simu.M_grid)**(1./simu.d))\n        test_m = centers - eps*normals\n        test_p = centers + eps*normals\n        lab_test_m = belongs_to(simu,test_m)\n        lab_test_p = belongs_to(simu,test_p)\n        tm_fst = lab_test_m == lab[:,0]\n        tm_scd = lab_test_m == lab[:,1]\n        tp_fst = lab_test_p == lab[:,0]\n        tp_scd = lab_test_p == lab[:,1]\n        tm_out = ((test_m.max(dim=1).values>1) | (test_m.min(dim=1).values<0))\n        tp_out = ((test_p.max(dim=1).values>1) | (test_p.min(dim=1).values<0))    \n        out = (tm_out & tp_scd) | (tm_out & tp_fst) | (tm_fst & tp_out) | (tm_scd & tp_out)\n        \n        good = (((tm_fst) & (tp_scd)) | ((tm_scd) & (tp_fst)) | out)\n        \n        to_reorient = ((tm_scd) & (tp_fst)) | (tp_out)\n        normals[to_reorient,:] *= -1\n        curv[to_reorient] *= -1\n        return normals[good], lab[good], area[good], curv[good], centers[good]\n        \n\n    def compute_forces(simu,normals,lab,area,curv,centers):\n        N = len(simu.x)\n        F = torch.zeros_like(simu.x)\n        g_ij = torch.zeros(len(lab))\n        g_ij[(lab[:,0]<N1) & (lab[:,1]>=N1)] = g12\n        g_ij[(lab[:,1]<N1) & (lab[:,0]>=N1)] = g12\n        g_ij[(lab[:,0]<N1) & (lab[:,1]<N1)] = g11\n        g_ij[(lab[:,0]>=N1) & (lab[:,1]>=N1)] = g22\n\n        g_ij[(lab[:,0]==-1) & (lab[:,1]<N1)] = g10\n        g_ij[(lab[:,0]==-1) & (lab[:,1]>=N1)] = g20\n        g_ij[(lab[:,1]==-1) & (lab[:,0]<N1)] = g10\n        g_ij[(lab[:,1]==-1) & (lab[:,0]>=N1)] = g20\n\n        g_ij[(lab[:,0]==-2) | (lab[:,1]==-2)] = gb\n        \n        \n        b_ij = torch.zeros(len(lab))\n        b_ij[(lab[:,0]<N1) & (lab[:,1]>=N1)] = b12\n        b_ij[(lab[:,1]<N1) & (lab[:,0]>=N1)] = b12\n        b_ij[(lab[:,0]<N1) & (lab[:,1]<N1)] = b11\n        b_ij[(lab[:,0]>=N1) & (lab[:,1]>=N1)] = b22\n\n        b_ij[(lab[:,0]==-1) & (lab[:,1]<N1)] = 0\n        b_ij[(lab[:,0]==-1) & (lab[:,1]>=N1)] = 0\n        b_ij[(lab[:,1]==-1) & (lab[:,0]<N1)] = 0\n        b_ij[(lab[:,1]==-1) & (lab[:,0]>=N1)] = 0\n\n        b_ij[(lab[:,0]==-2) | (lab[:,1]==-2)] = gb\n        \n        \n        for i in range(N):\n            fst = lab[:,0] == i\n            scd = lab[:,1] == i\n            \n            # Curvature force\n            \n            F_crv_fst = (-normals[fst,:]*curv[fst,None].abs()*area[fst,None]*g_ij[fst,None]).sum(0) \n            F_crv_scd = (normals[scd,:]*curv[scd,None].abs()*area[scd,None]*g_ij[scd,None]).sum(0)\n            F_crv = F_crv_fst + F_crv_scd\n            \n            # Boundary force\n            fst_bnd = fst & (lab[:,1]==-2)\n            scd_bnd = scd & (lab[:,0]==-2)\n            F_bnd_fst = (-normals[fst_bnd,:]*area[fst_bnd,None]*g_ij[fst_bnd,None]).sum(0)\n            F_bnd_scd = (normals[scd_bnd,:]*area[scd_bnd,None]*g_ij[scd_bnd,None]).sum(0)\n            F_bnd = F_bnd_fst + F_bnd_scd\n\n            # Positional force\n\n            fst_ij = fst & (lab[:,1]>=0)\n            scd_ji = scd & (lab[:,0]>=0)\n\n            d_ij = torch.maximum(torch.norm(simu.x[i,:] - simu.x[lab[fst_ij,1].int(),:],dim=1),torch.tensor(0.01))\n            F_pos_ij = (-normals[fst_ij,:]*area[fst_ij,None]*1.0/d_ij[:,None]*b_ij[fst_ij,None]).sum(0)\n\n            d_ji = torch.maximum(torch.norm(simu.x[i,:] - simu.x[lab[scd_ji,0].int(),:],dim=1),torch.tensor(0.01))\n            F_pos_ji = (normals[scd_ji,:]*area[scd_ji,None]*1.0/d_ji[:,None]*b_ij[scd_ji,None]).sum(0)\n            F_pos = F_pos_ij + F_pos_ji\n            \n            F[i,:] = F_pos + F_crv + F_bnd\n        \n        return F \n        \n    def neigh_list_to_cc(neigh_list):\n        cc = []\n        cc_index = torch.zeros(N,dtype=neigh_list.dtype)\n        seen = torch.zeros(N,dtype=bool)\n\n        def add(b,index,cc,cc_index,seen):\n            cc[index].append(b)\n            seen[b] = True\n            cc_index[b] = index\n\n        def merge(i,j,cc,cc_index):\n            cc[i] = cc[i] + cc[j]\n            cc.pop(j)\n            for index,component in enumerate(cc): \n                cc_index[component] = index\n\n        for edge in neigh_list:\n            a = edge[0].item()\n            b = edge[1].item()\n            if seen[a] & (~seen[b]):\n                add(b,cc_index[a],cc,cc_index,seen)\n            elif seen[b] & (~seen[a]):\n                add(a,cc_index[b],cc,cc_index,seen)\n            elif (~seen[a]) & (~seen[b]):\n                cc.append([a,b])\n                cc_index[a] = len(cc) - 1\n                cc_index[b] = len(cc) - 1\n                seen[a] = True\n                seen[b] = True\n            else:\n                if (cc_index[a] != cc_index[b]):\n                    merge(cc_index[a],cc_index[b],cc,cc_index)\n                    \n        return cc, cc_index\n\n    def correction_force(F,lab):\n        F_correction = torch.zeros_like(F)\n        only_particles = (lab[:,0]>=0) & (lab[:,1]>=0)\n        lab_particles = lab[only_particles,:]\n        neigh_list = torch.unique(lab_particles,dim=0).to(device=lab.device,dtype=torch.long)\n        cc, _ = neigh_list_to_cc(neigh_list)\n        for component in cc:\n            F_correction[component,:] = -F[component,:].mean(dim=0)[None,:]\n        return F_correction\n        \n\n    #======================= INITIALISE ========================#\n\n    solver.solve(simu,\n                sinkhorn_algo=ot_algo,\n                tau=0.4,\n                to_bary=True,\n                show_progress=False,\n                default_init=False,\n                weight=1.0,\n                bsr=True)\n\n    img = simu.labels.reshape(M,M,M).cpu().numpy()\n    img[img==img.max()] = -1.0\n    surfaces = compute_mesh(img)\n\n    surfaces.save(simu_name + \"/data/\"+f\"t_{int(t_plot/save_every)}.vtk\")\n    img = np.pad(img,1,mode='constant',constant_values=-2.0)\n    tif.imwrite(simu_name + \"/data/\"+f\"t_{int(t_plot/save_every)}.tif\", img, bigtiff=True)\n\n    solver.cost_params[\"C\"] = sc\n\n    t += dt\n    t_iter += 1\n    t_plot += 1\n\n    #=========================== RUN ===========================#\n\n    while t<T:\n        print(\"--------------------------\",flush=True)\n        print(f\"t={t}\",flush=True)\n        print(\"--------------------------\",flush=True)\n\n        plotting_time = t_iter%plot_every==0\n\n        if plotting_time:\n            print(\"I plot.\",flush=True)\n            solver.n_sinkhorn_last = 2000\n            solver.n_sinkhorn = 2000\n            solver.s0 = 2.0\n        else:\n            print(\"I do not plot.\",flush=True)\n            solver.n_sinkhorn_last = 250\n            solver.n_sinkhorn = 250\n            solver.s0 = 2*simu.R_mean\n            \n        \n        F_inc = solver.lloyd_step(simu,\n                    sinkhorn_algo=OT.LBFGSB,\n                    tau=tau/(radius(simu)**(simu.d - 1)),\n                    to_bary=False,\n                    show_progress=False,\n                    default_init=False,bsr=True)\n        \n        img = simu.labels.reshape(M,M,M).cpu().numpy()\n        img[img==img.max()] = -1.0\n        surfaces = compute_mesh(img)\n        \n        stime = time.time()\n        stuff = extract_stuff(surfaces)\n        print(f\"Mesh extraction time: {time.time()-stime}\",flush=True)\n        \n        stime = time.time()\n        F_att = compute_forces(simu,*stuff)\n        print(f\"Force computation time: {time.time()-stime}\",flush=True)\n        \n        stime = time.time()\n        F_correct = correction_force(F_att,stuff[1])\n        # F_correct = torch.tensor([[0.0,0.0,0.0]])\n        print(f\"Correction force computation time: {time.time()-stime}\",flush=True)\n        \n        simu.x += F_att*dt + F_inc*dt + F_correct*dt\n        \n        print(f\"Maximal incompressibility force: {torch.max(torch.norm(F_inc,dim=1))}\",flush=True)\n        print(f\"Maximal attraction force: {torch.max(torch.norm(F_att,dim=1))}\",flush=True)\n        print(f\"Mean attraction force: {torch.mean(torch.norm(F_att,dim=1))}\",flush=True)\n        print(f\"Maximal correction force: {torch.max(torch.norm(F_correct,dim=1))}\",flush=True)\n        print(f\"Mean correction force: {torch.mean(torch.norm(F_correct,dim=1))}\",flush=True)\n        print(f\"Maximal force: {torch.max(torch.norm(F_att + F_inc + F_correct,dim=1))}\",flush=True)\n        print(f\"Mean force: {torch.mean(torch.norm(F_att + F_inc + F_correct,dim=1))}\",flush=True)\n\n        \n        if plotting_time:\n            if t_plot%save_every==0:\n                surfaces.save(simu_name + \"/data/\"+f\"t_{int(t_plot/save_every)}.vtk\")\n                img = np.pad(img,1,mode='constant',constant_values=-2.0)\n                # tif.imwrite(simu_name + \"/data/\"+f\"t_{int(t_plot/save_every)}.tif\", img, bigtiff=True)\n            t_plot += 1\n\n        t += dt\n        t_iter += 1\n    \n    t_plot +=1 \n    surfaces.save(simu_name + \"/data/\"+f\"t_{int(t_plot/save_every)}.vtk\")\n    img = np.pad(img,1,mode='constant',constant_values=-2.0)\n    tif.imwrite(simu_name + \"/data/\"+f\"t_{int(t_plot/save_every)}.tif\", img, bigtiff=True)\n    with open(simu_name + \"/simu_final.pkl\",'wb') as file:\n        pickle.dump(simu,file)\n\ndef ratio_to_stparams(r_b1,r_g1,r_k1,g20=10.0):\n    params = {\n        \"r_b1\" : r_b1,\n        \"r_g1\" : r_g1,\n        \"r_k1\" : r_k1,\n        \"g20\" : g20\n    }\n    \n    k20 = 0.4\n    k12 = k20\n    params[\"gb\"] = g20\n    params[\"g11\"] = 0.0\n    params[\"g22\"] = 0.0\n    \n    k10 = r_k1 * k20 \n    params[\"g10\"] = r_g1 * g20 \n    \n    params[\"b11\"] = 2 * k10 * r_g1 * g20\n    params[\"b22\"] = 2 * k20 * g20\n    params[\"b12\"] = 2 * k10 * r_g1 * r_b1 * g20\n    params[\"g12\"] = k10/k12 * r_g1 * g20 \n    return params\n\n\nr_b1 = 3.0\nr_g1 = 1.0\nr_k1 = 1.0\nrun_simu(ratio_to_stparams(r_b1,r_g1,r_k1,g20=5.0),title=\"separation\")\n\n\nr_b1 = 0.3\nr_g1 = 1.0\nr_k1 = 1.0\nrun_simu(ratio_to_stparams(r_b1,r_g1,r_k1,g20=5.0),title=\"checkerboard\")\n\n\nr_b1 = 3.0\nr_g1 = 2.0\nr_k1 = 0.8/(r_b1*r_g1)\nrun_simu(ratio_to_stparams(r_b1,r_g1,r_k1,g20=5.0),title=\"engulfment_bgeq1\")\n\nr_b1 = 0.3\nr_g1 = 2.0\nr_k1 = 0.8/r_g1\nrun_simu(ratio_to_stparams(r_b1,r_g1,r_k1,g20=5.0),title=\"engulfment_bleq1\")\n\n\nr_b1 = 3.0\nr_g1 = 2.0\nr_k1 = 0.8/(r_b1*r_g1)\nrun_simu(ratio_to_stparams(r_b1,r_g1,r_k1,g20=5.0),title=\"engulfment_bgeq1_split\",init=\"split\")\n\nr_b1 = 0.3\nr_g1 = 2.0\nr_k1 = 0.8/r_g1\nrun_simu(ratio_to_stparams(r_b1,r_g1,r_k1,g20=5.0),title=\"engulfment_bleq1_split\",init=\"split\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}